\section{Introducción}

\paragraph{Resumen del problema y enfoque}

El objetivo de esta entrega es entrenar y explicar un modelo \de árbol de decisión para predecir la variable \texttt{recid}. El flujo de trabajo es sencillo para esta entrega es sencillo: EDA breve para identificar características de los datos, preprocesamiento encapsulado en \texttt{Pipeline} con \texttt{ColumnTransformer}, un primer modelo \emph{baseline} sin ajuste y un segundo modelo con los hiperpaámetros ajustados mediante \texttt{GridSearch}. Al final se presentan los resultados de ambos modelos y se estduia la explicabilidad global y local del modelo ajustado.

\paragraph{Datos (características y procesamiento)}
Trabajamos con el conjunto \texttt{recidivism.csv}, con \texttt{recid} como variable objetivo (binaria) y el resto de variables numéricas y categóricas. El EDA se centra en calidad de datos (nulos, cardinalidad) y equilibrio de clases (proporciones e \emph{Imbalance Ratio} de \textbf{1.14}). El preprocesamiento separa variables numéricas (\emph{passthrough}) y categóricas (codificación One-Hot), todo dentro de un \texttt{Pipeline} para evitar \emph{leakage} y garantizar que las mismas transformaciones se apliquen en validación y test.

\paragraph{Resultados (visión general)}
El \emph{baseline} sin ajuste alcanza \(\sim\)0.66 de \emph{accuracy} en validación. Tras el \texttt{GridSearch}, el mejor árbol obtiene en test \(\sim\)0.70 de \emph{accuracy} y mejora de forma consistente las métricas por clase (\textbf{precision}, \textbf{recall} y \textbf{F1}). Además, el ajuste produce un modelo más \textbf{explicable a nivel global}: el árbol es más compacto (menor profundidad y menos reglas), se puede \emph{pintar} y recorrer con claridad, y facilita la extracción de reglas comprensibles; a nivel local, las rutas de decisión son más cortas y fáciles de justificar.



