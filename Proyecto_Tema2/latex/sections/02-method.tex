\section{Metodología}

\subsubsection{Árbol baseline (referencia)}
Como primer paso se entrena un \texttt{DecisionTreeClassifier} con parámetros por defecto dentro del \texttt{Pipeline}. Este modelo sirve como modelo de referencia para responder a dos preguntas: (i) si la representación y el preprocesado son adecuados (el árbol aprende patrones sin necesidad de ingeniería adicional), y (ii) cuánto aporta realmente el ajuste de hiperparámetros. La elección de un árbol como baseline se justifica por su \textbf{transparencia inmediata} (reglas y estructura legibles) y por su bajo coste computacional.

\subsubsection{Árbol ajustado (GridSearchCV)}
En un segundo paso se ajusta el mismo clasificador mediante \texttt{GridSearch} con validación cruzada (5 particiones). La rejilla explora hiperparámetros que controlan el compromiso sesgo–varianza y la legibilidad del árbol:

\begin{itemize}
  \item \textbf{\texttt{max\_depth}}: limita la profundidad para reducir sobreajuste.
  \item \textbf{\texttt{min\_samples\_leaf}} y \textbf{\texttt{min\_samples\_split}}: evitan hojas muy pequeñas, estabilizando reglas y mejorando la generalización.
  \item \textbf{\texttt{criterion} (gini, entropy, log\_loss}: distintos criterios de división; \texttt{log\_loss} tiende a probabilidades más informativas, \texttt{gini}/\texttt{entropy} suelen ser más rápidos.
  \item \textbf{\texttt{max\_features} (None, sqrt, log2)}: puede actuar como regularizador al limitar atributos por división; en un único árbol se prioriza la \textbf{determinación} y legibilidad (\texttt{None}) salvo que limitarlo mejore validación.
  \item \textbf{\texttt{splitter} (best, random)}: \texttt{best} ofrece divisiones deterministas y normalmente mejores; \texttt{random} solo si se busca explorar particiones alternativas.
\end{itemize}

\paragraph{Configuración ganadora.}
Conforme al criterio de selección empleado, la mejor configuración obtenida fue:

\begin{table}[h]
\centering
\label{tab:best-params}
\small
\begin{tabular}{@{}ll@{}}
\toprule
\textbf{Parámetro}              & \textbf{Valor} \\ \midrule
\texttt{criterion}              & \texttt{gini} \\
\texttt{max\_depth}             & \texttt{3} \\
\texttt{min\_samples\_leaf}     & \texttt{1} \\
\texttt{min\_samples\_split}    & \texttt{2} \\
\texttt{max\_features}          & \texttt{None} \\
\texttt{class\_weight}          & \texttt{None} \\
\texttt{splitter}               & \texttt{best} \\ \bottomrule
\end{tabular}
\caption{Hiperparámetros óptimos devueltos por \texttt{GridSearchCV}.}
\end{table}
% Sustituir los <rellenar> por los valores que devuelve GridSearchCV.best_params_

Esta configuración \textbf{mejora} las métricas de evaluación frente al baseline (precision, recall y F1 por clase) y, al imponer \texttt{max\_depth} y un \texttt{min\_samples\_leaf} menor, produce un árbol \textbf{más compacto y explicable}: menos nodos/hojas, reglas más cortas y un diagrama del árbol que se puede \emph{pintar} y recorrer con claridad.

