\section{Discusión}

\subsection*{Rendimiento}
El modelo ajustado mejora frente al baseline: \textbf{Accuracy} de $\sim$0.66 $\rightarrow$ $\sim$0.70 y subida en \textbf{F1 (macro)}. La \textbf{5-fold CV} (0.719) es coherente con esa ganancia, por lo que no parece un efecto aleatorio. A nivel de errores, se reducen falsos negativos sin un aumento desmedido de falsos positivos.

\subsection*{Interpretabilidad}
El árbol resultante es \textbf{más compacto} (poca profundidad y menos reglas), se puede dibujar y leer de arriba a abajo, y las primeras decisiones (\texttt{employment\_unemployed} $\rightarrow$ \texttt{priors\_count} $\rightarrow$ \texttt{age}) se repiten de forma clara. Las rutas locales son cortas y alineadas con esas reglas globales, lo que facilita explicar casos concretos.

\subsection*{Mejora encadenada (qué haríamos a continuación)}
\begin{enumerate}
  \item \textbf{Primero, aumentar precisión} sin romper la estructura: ampliar ligeramente la rejilla (p.\,ej., ajustes finos de \texttt{max\_depth} y \texttt{min\_samples\_leaf}) manteniendo límites de complejidad para no inflar el árbol. El objetivo es ganar algunos puntos en \textit{Accuracy}/\textit{F1} con cambios controlados.
  \item \textbf{Después, asegurar la explicabilidad}: comprobar que la profundidad, el nº de nodos/hojas y el nº de reglas se mantienen en rango “leíble”. Si creciera demasiado, aplicar poda suave (p.\,ej., \texttt{ccp\_alpha}) o volver a restricciones más estrictas. En el \emph{informe}, se pueden redondear umbrales altos para lectura; no tocar cortes sensibles como 2.5.
  \item \textbf{Por último, ajustar por clases}: con el modelo estabilizado, calibrar probabilidades y mover el umbral de decisión si se prioriza reducir falsos negativos, validándolo con \textbf{F1 (macro)} y curvas PR. La idea es afinar el equilibrio sin perder la claridad ganada.
\end{enumerate}

